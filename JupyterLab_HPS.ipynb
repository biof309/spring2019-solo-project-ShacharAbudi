{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hermansky Pudlak Syndrome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![FirstPic](images/Picture1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SecondPic](images/Picture2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ThirdPic](images/Picture3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SecondPic](images/Picture4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SecondPic](images/Picture5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SecondPic](images/Picture6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SecondPic](images/Picture7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning \n",
    "1. Creating a training dataset (1000 each group)\n",
    "2. Defining a neural network model \n",
    "3. Training the model\n",
    "4. Classify lung histology slides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = Sequential()\n",
    "\t\tinputShape = (height, width, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add layers- filters, activation relu/softmax, dropout\n",
    "keras.layers.Add()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SecondPic](images/Picture8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layer\n",
    "\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "\tinput_shape=inputShape))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\n",
    "# Second layer\n",
    "\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\n",
    "# Third layer\n",
    "\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\n",
    "# Last layer\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1024))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(classes))\n",
    "\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "# return the constructed network architecture\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import matplotlib\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyimagesearch.smallervggnet import SmallerVGGNet\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "# imutils- image processing \n",
    "import numpy as np\n",
    "import argparse\n",
    "#argparse-let the user of your program provide values for variables at runtime\n",
    "import random\n",
    "import pickle\n",
    "#pickle-for serializing and de-serializing a Python object structure\n",
    "import cv2\n",
    "# cv2- read images, display images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the arguments- dataset of images, model \n",
    "ap = argparse.ArgumentParser()\n",
    "# initialize the number of epochs to train for, initial learning rate and image dimensions\n",
    "EPOCHS = 100\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "IMAGE_DIMS = (96, 96, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the input images and costumize them\n",
    "for imagePath in imagePaths:\n",
    "image = cv2.imread(imagePath)\n",
    "image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "image = img_to_array(image)\n",
    "data.append(image)\n",
    "label = imagePath.split(os.path.sep)[-2]\n",
    "labels.append(label)\n",
    "\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# partition the data into training and testing splits using 80% of the data for training \n",
    "# and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = SmallerVGGNet.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],depth=IMAGE_DIMS[2], classes=len(lb.classes_))\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(\n",
    "aug.flow(trainX, trainY, batch_size=BS),validation_data=(testX, testY),steps_per_epoch=len(trainX) // BS,epochs=EPOCHS, verbose=1)\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(args[\"model\"])\n",
    " \n",
    "# save the label binarizer to disk\n",
    "print(\"[INFO] serializing label binarizer...\")\n",
    "f = open(args[\"labelbin\"], \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Python\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(args[\"plot\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch=100\n",
    "![SecondPic](images/Picture9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SecondPic](images/Picture10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch=200\n",
    "![SecondPic](images/Picture11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SecondPic](images/Picture12.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the same necessary packages\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "\thelp=\"path to trained model model\")\n",
    "ap.add_argument(\"-l\", \"--labelbin\", required=True,\n",
    "\thelp=\"path to label binarizer\")\n",
    "ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "\thelp=\"path to input image\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image\n",
    "image = cv2.imread(args[\"image\"])\n",
    "output = image.copy()\n",
    " \n",
    "# pre-process the image for classification\n",
    "image = cv2.resize(image, (96, 96))\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained convolutional neural network\n",
    "print(\"[INFO] loading network...\")\n",
    "model = load_model(args[\"model\"])\n",
    "lb = pickle.loads(open(args[\"labelbin\"], \"rb\").read())\n",
    " \n",
    "# classify the input image\n",
    "print(\"[INFO] classifying image...\")\n",
    "proba = model.predict(image)[0]\n",
    "idx = np.argmax(proba)\n",
    "label = lb.classes_[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"correct\" is if there is the same input image filename\n",
    "filename = args[\"image\"][args[\"image\"].rfind(os.path.sep) + 1:]\n",
    "correct = \"correct\" if filename.rfind(label) != -1 else \"incorrect\"\n",
    " \n",
    "# build the label and draw the label on the image\n",
    "label = \"{}: {:.2f}% ({})\".format(label, proba[idx] * 100, correct)\n",
    "output = imutils.resize(output, width=400)\n",
    "cv2.putText(output, label, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t0.7, (0, 255, 0), 2)\n",
    " \n",
    "# show the output image\n",
    "print(\"[INFO] {}\".format(label))\n",
    "cv2.imshow(\"Output\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal lung slide:\n",
    "![SecondPic](images/Picture15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fibrotic lung slide:\n",
    "![SecondPic](images/Picture14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mild fibrotic lung slide:\n",
    "![SecondPic](images/Picture16.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
