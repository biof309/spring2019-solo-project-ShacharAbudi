{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hermansky Pudlak Syndrome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/Picture1.png\" width=\"700\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/Picture2.png\" width=\"1000\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/Picture3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/Picture4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/Picture5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/Picture6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/Picture7.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/Picture19.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/Picture20.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep learning \n",
    "1. **Creating a training dataset (1000 each group)** - IMPORT\n",
    "<br><br>\n",
    "2. Instantiate\n",
    "<br><br>\n",
    "3. Training the model- FIT\n",
    "<br><br>\n",
    "4. Classify lung histology slides- PREDICT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep learning \n",
    "\n",
    "1. Creating a training dataset (1000 each group) - IMPORT\n",
    "<br><br>\n",
    "2. **Instantiate**\n",
    "<br><br>\n",
    "3. Training the model- FIT\n",
    "<br><br>\n",
    "4. Classify lung histology slides- PREDICT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# import the necessary packages from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = Sequential()\n",
    "\t\tinputShape = (height, width, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# add layers- filters, activation relu/softmax, dropout\n",
    "keras.layers.Add()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![SecondPic](images/Picture8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/Picture17.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/Picture18.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# First layer\n",
    "\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "\tinput_shape=inputShape))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\n",
    "# Second layer\n",
    "\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Third layer\n",
    "\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\n",
    "# Last layer\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1024))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(classes))\n",
    "\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "# return the constructed network architecture\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep learning \n",
    "\n",
    "1. Creating a training dataset (1000 each group) - IMPORT\n",
    "<br><br>\n",
    "2. Instantiate\n",
    "<br><br>\n",
    "3. **Training the model- FIT**\n",
    "<br><br>\n",
    "4. Classify lung histology slides- PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import matplotlib\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyimagesearch.smallervggnet import SmallerVGGNet\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "# imutils- image processing \n",
    "import numpy as np\n",
    "import argparse\n",
    "#argparse-let the user of your program provide values for variables at runtime\n",
    "import random\n",
    "import pickle\n",
    "#pickle-for serializing and de-serializing a Python object structure\n",
    "import cv2\n",
    "# cv2- read images, display images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# construct the arguments- dataset of images, model \n",
    "ap = argparse.ArgumentParser()\n",
    "# initialize the number of epochs to train for, initial learning rate and image dimensions\n",
    "EPOCHS = 100\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "IMAGE_DIMS = (96, 96, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# loop over the input images and costumize them\n",
    "for imagePath in imagePaths:\n",
    "image = cv2.imread(imagePath)\n",
    "image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "image = img_to_array(image)\n",
    "data.append(image)\n",
    "label = imagePath.split(os.path.sep)[-2]\n",
    "labels.append(label)\n",
    "\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "# partition the data into training and testing splits using 80% of the data for training \n",
    "# and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = SmallerVGGNet.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],depth=IMAGE_DIMS[2], classes=len(lb.classes_))\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator()\n",
    "aug.flow(trainX, trainY, batch_size=BS),validation_data=(testX, testY),steps_per_epoch=len(trainX) // BS,epochs=EPOCHS, verbose=1)\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(args[\"model\"])\n",
    " \n",
    "# save the label binarizer to disk\n",
    "print(\"[INFO] serializing label binarizer...\")\n",
    "f = open(args[\"labelbin\"], \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(args[\"plot\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Epoch=100\n",
    "![SecondPic](images/Picture9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![SecondPic](images/Picture10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Epoch=200\n",
    "![SecondPic](images/Picture11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![SecondPic](images/Picture12.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 80% of the data for training \n",
    "# and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![SecondPic](images/Picture21.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "\tlabels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![SecondPic](images/Picture22.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep learning \n",
    "\n",
    "1. Creating a training dataset (1000 each group) - IMPORT\n",
    "<br><br>\n",
    "2. Instantiate\n",
    "<br><br>\n",
    "3. Training the model- FIT\n",
    "<br><br>\n",
    "4. **Classify lung histology slides- PREDICT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# import the same necessary packages\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "\thelp=\"path to trained model model\")\n",
    "ap.add_argument(\"-l\", \"--labelbin\", required=True,\n",
    "\thelp=\"path to label binarizer\")\n",
    "ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "\thelp=\"path to input image\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# load the image\n",
    "image = cv2.imread(args[\"image\"])\n",
    "output = image.copy()\n",
    " \n",
    "# pre-process the image for classification\n",
    "image = cv2.resize(image, (96, 96))\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# load the trained convolutional neural network\n",
    "print(\"[INFO] loading network...\")\n",
    "model = load_model(args[\"model\"])\n",
    "lb = pickle.loads(open(args[\"labelbin\"], \"rb\").read())\n",
    " \n",
    "# classify the input image\n",
    "print(\"[INFO] classifying image...\")\n",
    "proba = model.predict(image)[0]\n",
    "idx = np.argmax(proba)\n",
    "label = lb.classes_[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#\"correct\" is if there is the same input image filename\n",
    "filename = args[\"image\"][args[\"image\"].rfind(os.path.sep) + 1:]\n",
    "correct = \"correct\" if filename.rfind(label) != -1 else \"incorrect\"\n",
    " \n",
    "# build the label and draw the label on the image\n",
    "label = \"{}: {:.2f}% ({})\".format(label, proba[idx] * 100, correct)\n",
    "output = imutils.resize(output, width=400)\n",
    "cv2.putText(output, label, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t0.7, (0, 255, 0), 2)\n",
    " \n",
    "# show the output image\n",
    "print(\"[INFO] {}\".format(label))\n",
    "cv2.imshow(\"Output\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Normal lung slide:\n",
    "![SecondPic](images/Picture15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fibrotic lung slide:\n",
    "![SecondPic](images/Picture14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mild fibrotic lung slide:\n",
    "![SecondPic](images/Picture16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Limitations\n",
    "\n",
    "1. Blood Vessels\n",
    "<br><br>\n",
    "2. Uninflated ares\n",
    "<br><br>\n",
    "3. Tissue rapture\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SecondPic](images/Picture23.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "# initialize the list\n",
    "# cropping is being performed or not\n",
    "refPt = []\n",
    "cropping = False\n",
    "\n",
    "def click_and_crop(event, x, y, flags, param):\n",
    "\tglobal refPt, cropping\n",
    "\n",
    "\t# if the left mouse button was clicked, record the starting\n",
    "\t# (x, y) coordinates and indicate that cropping is being\n",
    "\t# performed\n",
    "\tif event == cv2.EVENT_LBUTTONDOWN:\n",
    "\t\trefPt = [(x, y)]\n",
    "\t\tcropping = True\n",
    "\n",
    "\t# check to see if the left mouse button was released\n",
    "\telif event == cv2.EVENT_LBUTTONUP:\n",
    "\t\t# record the ending (x, y) coordinates and indicate that\n",
    "\t\t# the cropping operation is finished\n",
    "\t\trefPt.append((x, y))\n",
    "\t\tcropping = False\n",
    "\n",
    "\t\t# draw a rectangle around the region of interest\n",
    "\t\tcv2.rectangle(image, refPt[0], refPt[1], (0, 255, 0), 2)\n",
    "\t\tcv2.imshow(\"image\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# keep looping until the 'q' key is pressed\n",
    "while True:\n",
    "\t# display the image and wait for a keypress\n",
    "\tcv2.imshow(\"image\", image)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\t# if the 'r' key is pressed, reset the cropping region\n",
    "\tif key == ord(\"r\"):\n",
    "\t\timage = clone.copy()\n",
    "\n",
    "\t# if the 'c' key is pressed, break from the loop\n",
    "\telif key == ord(\"c\"):\n",
    "\t\tbreak\n",
    "\n",
    "\n",
    "# if there are two reference points, then crop the region of interest\n",
    "# from teh image and display it\n",
    "if len(refPt) == 2:\n",
    "\tnew_image = clone[refPt[0][1]:refPt[1][1], refPt[0][0]:refPt[1][0]]\n",
    "\tcv2.imshow(\"Your new Image\", new_image)\n",
    "\tcv2.imwrite(\"new_image.jpg\", new_image)\n",
    "\tcv2.waitKey(0)\n",
    "\n",
    "# close all open windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SecondPic](images/Picture24.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SecondPic](images/Picture25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# New problem: new images are at different sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# receive new image\n",
    "image = cv2.imread(\"new_image.jpg\")\n",
    "print (image.shape)\n",
    "\n",
    "# calculate the ratio of the new image to the old image\n",
    "r = 60.0/ image.shape[1]\n",
    "dim = (60, int(image.shape[0] * r))\n",
    "\n",
    "# perform the actual resizing of the image and show it\n",
    "resized = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow(\"resized\", resized)\n",
    "cv2.imwrite(\"new_image.jpg\", resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![SecondPic](images/Picture26.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Next Steps\n",
    "\n",
    "1. Incresing our data \n",
    "<br><br>\n",
    "2. Using machine learning to evaluate our data dimensions \n",
    "<br><br>\n",
    "3. Changing to a user-friendly platform \n",
    "<br><br>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
